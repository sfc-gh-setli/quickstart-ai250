{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ghkip22uoq5cetz2zjls",
   "authorId": "547381728337",
   "authorName": "ADMIN",
   "authorEmail": "mats.stellwall@snowflake.com",
   "sessionId": "7ce7b94c-807c-4111-a9eb-c745ba9e44a0",
   "lastEditTime": 1738333323295
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "8b3e3fe0-c477-42c5-a3e3-554712bd9647",
   "metadata": {
    "language": "python",
    "name": "py_headline",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nst.markdown(\"\"\"\n<div style=\"background-color: #000020; color: white; text-align: center; padding: 20px\">\n  <h1 style=\"margin: 0; color: white\"><b>Questioning the Answers: LLMs enter the Boardroom</b></h1>\n  <h2 style=\"margin: 0; color: white\"><b></b>Using Gen AI Tools to Harness Alpha from Earnings Calls</h2>\n  <h3 style=\"margin: 0; color: white\"><b>by S&P Global Market Intelligence's Quantitative Research & Solutions (QRS) Group</b></h3>\n</div>\n\"\"\", unsafe_allow_html=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "04b2912a-e563-47a2-8731-7bba38772e76",
   "metadata": {
    "name": "md_1_overview",
    "collapsed": false
   },
   "source": "# 1. Overview\nEarnings calls play a pivotal role in shaping investor perceptions. The quality of communication between executives and analysts can significantly influence company performance. Efficient Communicators—executives who deliver proactive presentations, anticipate market queries, and provide clear, on-topic answers to analysts’ questions—consistently outperform their peers. Conversely, Total Redirectors—executives who are reactive, fail to address analysts’ key inquiries during presentations, and provide off-topic responses—significantly underperform.\n\nExecutives' ability to anticipate investor concerns and maintain a focused dialogue fosters confidence and strategic communication. In contrast, failing to provide clarity when analysts seek additional information can lead to misalignment and breakdowns in transparency. A long (short) portfolio of Efficient Communicators (Total Redirectors) generates +515bps of annualized alpha.\n\nThis notebook serves as the blueprint for the research detailed in Quantitative Research & Solutions’ recent publication, [\"Questioninig the Answers: LLM's enter the Boardroom.\"](https://www.spglobal.com/market-intelligence/en/news-insights/research/questioning-the-answers-llms-enter-the-boardroom) It analyse executive on-topicness and proactiveness using the analysts questions, executives answers and LLM answers. This research harness alpha using LLM tools, including vector embeddings, vector cosine similarity, and the LLM quesiton answering."
  },
  {
   "cell_type": "markdown",
   "id": "f5a4c140-634d-4a3d-9db3-bf2febbbbafc",
   "metadata": {
    "name": "md_2_datasets",
    "collapsed": false
   },
   "source": "# 2. Datasets\n\nThis notebook is using data from the following datasets from the Snowflake Marketplace from S&P Global Market Intelligence:\n\n|Name|Description |\n|----|----|\n|[ S&P Capital IQ Financials](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D2N/s-p-global-market-intelligence-s-p-capital-iq-financials)|S&P Capital IQ Financials provides global standardized financial statement data for over 180,000 companies, including over 95,000 active and inactive public companies, and As Reported data for over 150,000 companies. S&P Capital IQ Standardized Financials allows you to extend the scope of your historical analysis and back-testing models with consistent data from all filings of a company's historical financial periods including press releases, original filings, and all restatements.|\n|[Global Events](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D38/s-p-global-market-intelligence-global-events)|The Global Events dataset provides details on upcoming and past corporate events such as earnings calls, shareholder/analyst meetings, expected earnings release dates and more. With deep history back to 2003, clients can leverage this dataset to derive signals and support trading models across asset classes, trading styles and frequencies. This dataset also helps in research & analysis, risk management & compliance, and trade surveillance workflows.|\n|[Machine Readable Transcripts](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D2V/s-p-global-market-intelligence-machine-readable-transcripts)|The Machine Readable Transcripts dataset aggregates data from earnings calls delivered in a machine-readable format for Natural Language Processing (NLP) applications with metadata tagging. Leverage Machine Readable Transcripts to keep track of event information for specific companies including dates, times, dial-in and replay numbers and investor relations contact information. Easily combine data from earnings, M&A, guidance, shareholder, company conference presentations and special calls with traditional datasets to develop proprietary analytics.|\n|[Compustat® Financials](https://app.snowflake.com/marketplace/listing/GZT0Z8P3D2R/s-p-global-market-intelligence-compustat®-financials)|Compustat Financials provides standardized North American and global financial statements and market data for over 80,000 active and inactive publicly traded companies that financial professionals have relied on for over 50 years. Compustat allows investment professionals, academic researchers, and industry analysts to combine deep history with robust and consistent data standardization into their research and backtesting to produce valuable insights and generate alpha. With historical data for North America as far back as 1950 and point-in-time snapshots beginning in 1987, Compustat provides you with insight into company financial performance across many different economic cycles not available anywhere else.|"
  },
  {
   "cell_type": "markdown",
   "id": "fa040835-3299-4600-b06f-9a47ff3312f7",
   "metadata": {
    "name": "md_3_libraries",
    "collapsed": false
   },
   "source": "# 3. Libraries & User Inputs\nImport libraries required for the workflow\n\n## 3.1 Libraries\n\nBefore running, mak sure you have added **cachetools** through **packages**"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "py_imports",
    "codeCollapsed": false,
    "collapsed": false
   },
   "source": "# Import python packages\nfrom datetime import datetime\nimport cachetools\n\nfrom snowflake.snowpark import functions as snow_funcs\nfrom snowflake.snowpark import Window\nfrom snowflake.snowpark.types import ArrayType, StringType\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4187b8f-34a3-402c-8c63-96623f676453",
   "metadata": {
    "name": "md_32_user_inputs",
    "collapsed": false
   },
   "source": "## 3.2 User Inputs\n\nThis research invloves the usage of an embedding model and a completion model, the default models were set to \"snowflake-arctic-embed-m\" for embedding and \"llama3.1-8b\" for completion. This user input section gives you the flexibility to chose your own model for the task."
  },
  {
   "cell_type": "code",
   "id": "fe9edb8d-b06e-4394-acd8-ba517c9b98d6",
   "metadata": {
    "language": "python",
    "name": "py_user_inputs",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Which of the two embedding functions we want to use\nsnf_embed_text_func = \"SNOWFLAKE.CORTEX.EMBED_TEXT_768\" \n\n# Which embedding model we want to use, see https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability \n# for avalible embedding models in Snowflake\nembedding_model = \"snowflake-arctic-embed-m\" \n\n# Which LLM we want to use, see https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions#availability \n# for avalible LLMs in Snowflake\ncompletion_model = \"llama3.1-8b\" \n\n# Name of the databse created in the Setup Snowflake step\nsp_llm_qs_location = \"SP_LLM_QS.PUBLIC\"\n\n# Name of the shared database created at the \"Request the S&P Global Market Intelligence QuickStart dataset\" step\nsp_qs_share_location = \"XF_SNOWFLAKE_QUICKSTRAT.XPRESSFEED\"",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12093f26-3af9-4808-8693-9a907b471bb9",
   "metadata": {
    "name": "md_33_date_dimension",
    "collapsed": false
   },
   "source": "## 3.3 Date Dimension"
  },
  {
   "cell_type": "code",
   "id": "43a2077b-7605-4f4e-8fa9-7651eb1a5c23",
   "metadata": {
    "language": "python",
    "name": "py_create_date_dimension",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nbeginDate = '2000-01-01' #start of period for analysis\nendDate = '2025-12-31' #end of period for analysis\n\nnbr_of_days = (datetime.strptime(endDate, \"%Y-%m-%d\") - datetime.strptime(beginDate, \"%Y-%m-%d\")).days\n\n\ncalendar_df = (session.generator(snow_funcs.to_date(snow_funcs.dateadd(\"DAY\", snow_funcs.call_function(\"SEQ4\"), snow_funcs.lit(beginDate))).as_(\"Date\"), rowcount=nbr_of_days)\n               .with_columns([\"Year\", \"Month\", \"Day\", \"Quarter\"],\n                                  [snow_funcs.year(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.month(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.dayofyear(snow_funcs.col(\"Date\"))\n                                   , snow_funcs.quarter(snow_funcs.col(\"Date\"))\n                                   , \n                                  ])\n               .with_columns(['FirstDayOfQuarter', 'LastDayOfQuarter']\n                            , [snow_funcs.min(snow_funcs.col('Date')).over(Window.partition_by(snow_funcs.col('year'), snow_funcs.col('quarter')))\n                              ,snow_funcs.last_day(snow_funcs.col('Date'), \"QUARTER\")])\n              )\n\ncalendar_df.create_or_replace_temp_view(f\"{sp_llm_qs_location}.date_dimension\")\ncalendar_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6fb673ab-7641-4655-8b90-f7472120011e",
   "metadata": {
    "name": "md_4_working_w_data",
    "collapsed": false
   },
   "source": "# 4. Working with the Data: Sample Company Transcript/S&P500 Transcripts\nIn this section we prepare the transcripts in a structured format. For those with access to the Index data, uncomment and run section 4.1.2 for a systematic analysis on transcripts of S&P 500 constituents\n\n## 4.1 Transcript Data\nIn the cells below we set the date range for the analysis. The S&P 500 constituents/sample company list is collected and formatted to show the daily constituents, including their date and calendarYearQuarter.\n\n### 4.1.1 Sample Company\nBelow is using only one company, S&P Global Inc., that is avalible in the sample dataset, if you do have access to index data from S&P Global Market Intelligence you can use the code in section 4.1.2 to for example select all S&P 500 constituents"
  },
  {
   "cell_type": "code",
   "id": "245a5cab-36d2-434f-a5ca-14f471ccc0cb",
   "metadata": {
    "language": "python",
    "name": "py_company_info_sample",
    "collapsed": false
   },
   "outputs": [],
   "source": "df_indexcon = session.sql(f\"\"\"\n\n    select distinct\n    \n        c.companyId, c.companyName\n        , s.securityId\n        , ti.tradingItemId, 0 as indexId, 'Sample Index' as indexName, 0 as constituentId\n        , ti.tickerSymbol, 'NYSE' as exchangeSymbol\n        , concat('NYSE', ' : ', ti.tickerSymbol) as exchangeTicker\n        , to_date('1950-01-01') as fromDate, to_date('2050-12-31') as toDate\n    \n    from {sp_qs_share_location}.ciqTradingItem ti\n        join {sp_qs_share_location}.ciqExchange e on e.exchangeId=ti.exchangeId\n        join {sp_qs_share_location}.ciqSecurity s on s.securityId=ti.securityId\n        join (select companyId, companyName from {sp_qs_share_location}.ciqCompany c) c on c.companyId=s.companyId\n    where ti.tradingItemId in (\n        2629108 --S&P Global\n    ) \n\n\"\"\")\n\ndf_indexcon.write.save_as_table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT\", mode=\"overwrite\", table_type='transient')\ndf_indexcon.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e5e5449-7d34-4f0d-88cf-0bc070dd90c3",
   "metadata": {
    "name": "md_412_S_P_500",
    "collapsed": false
   },
   "source": "### 4.1.2 S&P500 Constituents\n\nBelow quesry can be used if you have access to Index data, make sure `sp_qs_share_location` has the database and schema name for where it is."
  },
  {
   "cell_type": "code",
   "id": "2ff3f821-08b3-4a2f-90fb-7b49d4fb98d2",
   "metadata": {
    "language": "python",
    "name": "py_412_S_P_500",
    "collapsed": false
   },
   "outputs": [],
   "source": "'''\n\ndf_indexcon = session.sql(f\"\"\"\n\n    select distinct\n    c.companyId, c.companyName\n    , s.securityId\n    , ic.tradingItemId, i.indexId, i.indexName, ic.constituentId\n    , ti.tickerSymbol, e.exchangeSymbol as exchangeSymbol\n    , concat(e.exchangeSymbol, ' : ', ti.tickerSymbol) as exchangeTicker\n    , to_date(ic.fromDate) as fromDate, to_date(ifnull(ic.toDate,current_date())) as toDate\n    \n    from {sp_qs_share_location}.ciqIndex i\n        join {sp_qs_share_location}.ciqindexConstituent ic on ic.indexId=i.indexId\n        join {sp_qs_share_location}.ciqTradingItem ti on ti.tradingItemId=ic.tradingItemId\n        join {sp_qs_share_location}.ciqExchange e on e.exchangeId=ti.exchangeId\n        join {sp_qs_share_location}.ciqSecurity s on s.securityId=ti.securityId\n        join (select companyId, companyName from {sp_qs_share_location}.ciqCompany c) c on c.companyId=s.companyId\n    where i.indexId in (\n    2668699 --S&P 500\n    --2668861 --S&P 100\n    ) \n\n\"\"\")\n\ndf_indexcon.write.save_as_table(f\"{progress_schema}.TRANSCRIPTHISTORYTOPRESENT\", mode=\"overwrite\", table_type='transient')\ndf_indexcon.limit(5)\n\n'''",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "02c32c1f-5f69-4056-8a76-c6f5ad2ab989",
   "metadata": {
    "name": "md_412_enrich_w_yq",
    "collapsed": false
   },
   "source": "### 4.1.2 Enrich Transcripts with calendar year quarter"
  },
  {
   "cell_type": "code",
   "id": "2d29287e-26a9-4b55-a7f9-9d07bbd0a1fa",
   "metadata": {
    "language": "python",
    "name": "py_enrich_w_yq",
    "collapsed": false
   },
   "outputs": [],
   "source": "df_indexcon = session.sql(f\"\"\"\n\n    select \n    \n        dd.firstDayOfQuarter, dd.lastDayOfQuarter,\n        concat(dd.year, '-', dd.quarter) as calendarYearQuarter,\n        concat(cp.fiscalYear, '-', cp.fiscalQuarter) as fiscalYearQuarter,\n        cpt.periodTypeName, cpt.periodTypeDescription,\n        r.companyId, r.companyName, r.tradingItemId\n        \n    from (select * from {sp_llm_qs_location}.DATE_DIMENSION where date = firstDayOfQuarter) dd\n        join {sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT r on dd.date between ifnull(r.fromDate, '1950-01-01') and ifnull(r.toDate, '2050-12-31')\n        join {sp_qs_share_location}.ciqFinPeriod cp on r.companyId = cp.companyId and dd.year = cp.calendarYear and dd.quarter = cp.calendarQuarter\n        join {sp_qs_share_location}.ciqEventPeriodType cpt on cp.periodTypeId = cpt.periodTypeId\n    \n    where 1=1\n        and date between '2000-01-01' and '2024-12-31'\n        and cp.periodTypeId = 2 --Fiscal/Calendar Quarter\n    order by calendarYearQuarter asc, companyId asc\n\n\"\"\")\n\ndf_indexcon.write.save_as_table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER\", mode=\"overwrite\", table_type='transient')\ndf_indexcon.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dc5541a-17eb-47a8-a202-689708e95229",
   "metadata": {
    "name": "md_42_machine_readable_transcripts",
    "collapsed": false
   },
   "source": "## 4.2 Machine Readable Transcripts\n### 4.2.1 Collect TranscriptId"
  },
  {
   "cell_type": "code",
   "id": "cfefac2b-f198-4737-9cd5-dad7f20f1062",
   "metadata": {
    "language": "python",
    "name": "py_get_transcriptid",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\ndf_transcript = session.sql(f\"\"\"\n                        \n    select * from \n    (select \n        ice.*, t.transcriptId, row_number() over (partition by fiscalYearQuarter, tradingItemId, ice.keyDevId order by t.transcriptCreationDateUTC desc) as latestTranscriptforKeyDev_Flag\n        \n    from\n    (select \n        ice.calendarYearQuarter, ice.fiscalYearQuarter, ice.tradingItemId, ice.companyId, ice.companyName, eot.keyDevId, e.headline\n        , e.mostImportantDateUTC, enteredDate, bi.periodEndDate, languageId, keydeveventtypeid\n        , row_number() over (partition by ice.tradingItemId, bi.fiscalYear, bi.fiscalQuarter order by e.lastModifiedDate desc) as latestKeyDev_Flag \n       from {sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER ice \n        join {sp_qs_share_location}.ciqEventToObjectToEventType eot on ice.companyId = eot.objectId and eot.keydeveventtypeid=48\n        join {sp_qs_share_location}.ciqEvent e on eot.keydevid = e.keydevid\n        join {sp_qs_share_location}.ciqEventCallBasicInfo bi on bi.keyDevId=e.KeyDevId and concat(bi.fiscalYear,'-',bi.fiscalQuarter) = ice.fiscalYearQuarter \n        \n    where bi.languageId in (0, 123) OR bi.languageId IS NULL --English\n    ) ice\n        left join {sp_qs_share_location}.ciqTranscript t on t.keyDevId=ice.keyDevId\n    where 1=1 \n        and t.transcriptId is not null\n        and latestKeyDev_Flag = 1)\n    where latestTranscriptforKeyDev_Flag = 1 \n    order by calendarYearQuarter asc, tradingItemId asc\n\n\"\"\")\n\ndf_transcript.write.save_as_table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TranscriptId\", mode=\"overwrite\", table_type='transient')\ndf_transcript.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5faadc21-2409-4e23-bb4b-f691a18fcee3",
   "metadata": {
    "name": "md_422_collect_transcript_components",
    "collapsed": false
   },
   "source": "### 4.2.2 Collect TranscriptId Components\nThis query collects all transcript components in the history."
  },
  {
   "cell_type": "code",
   "id": "335778ea-4eea-4ea4-a9e1-40bb3abfe59d",
   "metadata": {
    "language": "python",
    "name": "py_collect_transcript_components"
   },
   "outputs": [],
   "source": "\ndf_transcriptComponents = session.sql(f\"\"\"\n\n    select distinct \n        u.*\n        , speakerTypeName\n        , tp.transcriptPersonName\n        , tp.transcriptPersonId\n        , tp.proId\n        , ct.transcriptComponentTypeId\n        , transcriptComponentTypeName\n        , componentOrder\n        , transcriptComponentId\n        , componentText\n    \n    from\n    (select distinct to_date(mostImportantDateUTC) as callDate, to_date(enteredDate) as enteredDate, fiscalYearQuarter\n             , calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId \n             from {sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TranscriptId) u   \n        join {sp_llm_qs_location}.ciqTranscriptComponent tc on tc.transcriptId=u.transcriptId\n        join {sp_llm_qs_location}.ciqTranscriptComponentType ct on ct.transcriptComponentTypeId=tc.transcriptComponentTypeId\n        join {sp_llm_qs_location}.ciqTranscriptPerson tp on tp.transcriptPersonId=tc.transcriptPersonId\n        join {sp_llm_qs_location}.ciqTranscriptSpeakerType st on st.speakerTypeId=tp.speakerTypeId\n    order by companyId asc, callDate asc, transcriptId asc, componentOrder asc\n\n\"\"\")\n\ndf_transcriptComponents.write.save_as_table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TranscriptComponents\", mode=\"overwrite\", table_type='transient')\ndf_transcriptComponents.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1938e1f-147c-49f9-a609-b58b9ea769b9",
   "metadata": {
    "name": "md_423_coverage_check",
    "collapsed": false
   },
   "source": "### 4.2.3 Coverage Check"
  },
  {
   "cell_type": "code",
   "id": "a21b7952-c2ad-40f4-8b41-dd9f4ed3b1d1",
   "metadata": {
    "language": "sql",
    "name": "sql_coverage_check",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select calendarYearQuarter, count(distinct transcriptId) \nfrom {{sp_llm_qs_location}}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TranscriptComponents\ngroup by calendarYearQuarter \norder by calendarYearQuarter",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46d68789-dc5f-4bb6-ba5f-dbe16efe1546",
   "metadata": {
    "name": "md_5_Sentence_Tokenization",
    "collapsed": false
   },
   "source": "# 5. Working with the Data: Sentence Tokenization\nIn this section we tokenize the prepared remark and the answer components on the sentence level.\n\n## 5.1 Define Sentence Tokenization Function\n\nIn order to run the this step and the following you need to make sure you have created the  NETWORK RULE and  EXTERNAL ACCESS INTEGRATION objects in the **Create Database, Schema And Warehouse To Be Used** step of the quickstart guide.\n\nWe will use a Python User Defined Function (UDF) to do the tokenization using the NLTK library and set_tokenize.\n\nCreate a UDF to do the tokenizing."
  },
  {
   "cell_type": "code",
   "id": "4c98252b-160b-4895-80e4-db781831fbe3",
   "metadata": {
    "language": "python",
    "name": "py_define_udf",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Using @cachetools.cached ensures that we only download them once\n@cachetools.cached(cache={})\ndef download_files(save_path):\n    import nltk\n    import os\n    \n    os.environ['NLTK_DATA'] = save_path\n\n    # Create the directory if it doesn't exist\n    os.makedirs(save_path, exist_ok=True)\n\n    nltk.download('punkt', download_dir=save_path)\n    nltk.download('punkt_tab', download_dir=save_path) \n                \ndef sentenceTokenize(x):\n    import nltk\n    from nltk.tokenize import sent_tokenize\n\n    # Set the NLTK_DATA environment variable to the desired directory\n    nltk_data_dir = '/tmp/nltk_data'\n    nltk.data.path.append(nltk_data_dir)\n    download_files(nltk_data_dir)\n    \n    return sent_tokenize(x)\n\nsentence_tokenize_udf = snow_funcs.udf(sentenceTokenize\n                                       , return_type = ArrayType(StringType())\n                                       , input_types=[StringType()]\n                                      , packages=['nltk', 'cachetools']\n                                      , external_access_integrations=['NLTK_ACCESS_INTEGRATION'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "528b4698-32dd-43d1-a3ab-54479b9920bf",
   "metadata": {
    "name": "md_Apply_Tokenize_Function",
    "collapsed": false
   },
   "source": "## 5.2 Apply Tokenize Sentence Function\nThe code below tokenize all historical prepared remarks and executive answers into sentences.\n\n"
  },
  {
   "cell_type": "code",
   "id": "349adeec-304c-4c2f-bafe-caccb6b3fbfc",
   "metadata": {
    "language": "python",
    "name": "py_apply_tokenize_udf",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TRANSCRIPTCOMPONENTS\")\n\nfiltered_df = df.filter((snow_funcs.col('transcriptComponentTypeId') == 2) | (snow_funcs.col('transcriptComponentTypeId') == 4))\n\n# Apply the UDF to the DataFrame column\ndf_with_sentences = filtered_df.withColumn(\"sentencesList\", sentence_tokenize_udf(filtered_df[\"componentText\"])).cache_result()\n\n# Explode the sentencesList column and generate the order column\ndf_exploded = (df_with_sentences.select( *[col for col in df_with_sentences.columns if col != \"sentencesList\"]\n                          ,snow_funcs.flatten(snow_funcs.col(\"sentencesList\")).alias(\"SEQ\", \"KEY\", \"PATH\"\n                                                                                     ,  \"sentenceIndex\", \"sentence\", \"THIS\"))\n                .drop(\"SEQ\", \"KEY\", \"PATH\", \"THIS\")\n                .with_column(\"sentence\",snow_funcs.as_char(snow_funcs.col(\"sentence\")))\n              )\n\ndf_exploded.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_PPP_A_Sentences\", mode=\"overwrite\", table_type='transient')\ndf_exploded.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ed66a3e-f47b-4e7a-92b6-ffd992018e02",
   "metadata": {
    "name": "md_6_RAG",
    "collapsed": false
   },
   "source": "# 6. Working with the Data: Retrival Augmented Generation (RAG)\nRetrieval-Augmented Generation (RAG) is a tool that improves LLM consistency by retrieving relevant information before answering a question.\n\nFor this task the LLM needs to be as consistent as possible in its responses to the analysts’ questions as inconsistency will lead to variations in cosine similarity scores and disrupt feature generation downstream.\n\nTo combat this, we designed a Retrieval-Augmented Generation (RAG) engine that chunks the prepared remarks sentence-by-sentence and retrieves the optimal retrieval percentage of sentences most similar to the question. Inconsistency occurs when the LLM is provided with too little (or too much) context, it becomes uninformed (unspecific). The optimal retrieval percentage for consistency is 60%.\n\nIn the cells below, we vector embed all questions, prepared remark sentences and answer sentences using the snowflake-arctic-m embedding model. Then use the cosine similarity from the (question vs prepared remark sentences) and (question vs answer sentences) to select top 60% most relevant prepared remark and answer sentences to the question from S&P Global Q3 2024 Earnings Call Transcript\n\n## 6.1 S&P Global Q3 2024 Earnings Call Transcript\nSelect and seperate the prepared remarks, questions and answers sections of the S&P Global Q3 2024 Earnings Call"
  },
  {
   "cell_type": "code",
   "id": "164a0ce9-7d9e-40f2-b412-d0058ca3abcd",
   "metadata": {
    "language": "python",
    "name": "py_get_remarks_questions_answers",
    "collapsed": false
   },
   "outputs": [],
   "source": "sentences_df = session.table(f\"{sp_llm_qs_location}.TranscriptComponents_PPP_A_Sentences\")\nall_component_df = session.table(f\"{sp_llm_qs_location}.TRANSCRIPTHISTORYTOPRESENT_QUARTER_TRANSCRIPTCOMPONENTS\")\n\npppSentences = sentences_df.filter((snow_funcs.col('transcriptComponentTypeId') == 2) \n                                   & (snow_funcs.col('transcriptId') == 3291259)) ##Filter on S&P Global Q3 2024 Call\nquestions = all_component_df.filter((snow_funcs.col('transcriptComponentTypeId') == 3) \n                                    & (snow_funcs.col('transcriptId') == 3291259)) ##Filter on S&P Global Q3 2024 Call\nanswerSentences = sentences_df.filter((snow_funcs.col('transcriptComponentTypeId') == 4) \n                                      & (snow_funcs.col('transcriptId') == 3291259)) ##Filter on S&P Global Q3 2024 Call\n\nst.dataframe(pppSentences.limit(5))\nst.dataframe(questions.limit(5))\nst.dataframe(answerSentences.limit(5))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a7838f1-a7b4-430b-bc2f-e1fd32af6e44",
   "metadata": {
    "name": "md_62_Vector_Embedding",
    "collapsed": false
   },
   "source": "## 6.2 Vector Embedding\nTransform the questions, prepared remark sentences and answer sentences into numerical\nrepresentations using the snowflake-arctic-m embedding model.\n\n### 6.2.2 Apply Embedding to Transcript Components"
  },
  {
   "cell_type": "code",
   "id": "2b5eb4ac-7f94-48da-91b9-a407f3bdb5ca",
   "metadata": {
    "language": "python",
    "name": "py_create_components_embeddings",
    "collapsed": false
   },
   "outputs": [],
   "source": "snf_embed_text = snow_funcs.function(snf_embed_text_func)\n\npppSentences_with_embeddings = pppSentences.withColumn(\"sentenceVec\", snf_embed_text(snow_funcs.lit(embedding_model)\n                                                                                     ,pppSentences[\"sentence\"]))\nquestions_with_embeddings = questions.withColumn(\"componentTextVec\", snf_embed_text(snow_funcs.lit(embedding_model),\n                                                                                    questions[\"componentText\"]))\nanswerSentences_with_embeddings = answerSentences.withColumn(\"sentenceVec\",  snf_embed_text(snow_funcs.lit(embedding_model)\n                                                                                            ,answerSentences[\"sentence\"]))\n\npppSentences_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.pppSentencesVec\", mode=\"overwrite\",table_type='transient')\nquestions_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.questionsVec\", mode=\"overwrite\", table_type='transient')\nanswerSentences_with_embeddings.write.save_as_table(f\"{sp_llm_qs_location}.answerSentencesVec\", mode=\"overwrite\", table_type='transient')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aca42ae7-a9b7-4713-8c91-ee5148ef347c",
   "metadata": {
    "name": "md_63_Cosine_Similarity",
    "collapsed": false
   },
   "source": "# 6.3 Cosine Similarity\nTo determine semantic closeness, we vector-embed the question-and-answer texts and calculate a cosine similarity score between the two vectors.\nFor example, A and B each represent a vector such that:\n\n\n$$\tA = [a_1,a_2,… a_n] $$\n$$\tB = [b_1,b_2,… b_n] $$\n\n\nThe cosine similarity formula between vectors A and B is:\n\n$$\\text{Cosine Similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\cdot \\|\\mathbf{B}\\|}$$\n\n, where A⋅B is the dot product of the vectors, and |A|⋅|B| is the product of each vector's magnitude.\nThe result ranges from -1 to 1, where:\n\n\t-1: Vectors are opposite.\n\t0: Vectors are unrelated.\n\t1: Vectors are identical.\n\n### 6.3.2 Apply Cosine Similarity to Question & Answer Vector Embeddings\nThe cell below creates question and answer pair by collecting all the answer sentences whose componentOrder is between the currentQuestionComponentOrder and the nextQuestionComponentOrder. Then the the consine similarity was applied to the question and answer sentence vector embeddings."
  },
  {
   "cell_type": "code",
   "id": "0d879dde-2ff3-43da-bef4-493cd3621347",
   "metadata": {
    "language": "python",
    "name": "py_calc_cosine_sim_QA",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\nwith q as(\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter,\n        tradingItemId, companyId, companyName, headline, transcriptId,\n        speakerTypeName as questionSpeakerTypeName, transcriptPersonName as questionTranscriptPersonName,\n        transcriptPersonId as questionTranscriptPersonId, proId as questionProId, transcriptComponentTypeId as questionTranscriptComponentTypeId,\n        transcriptComponentId as questionTranscriptComponentId, componentOrder as currentQuestionOrder\n        , lead(componentOrder) over (partition by tradingItemId, transcriptId order by componentOrder) as nextQuestionOrder\n        , componentText as question, componentTextVec as questionVec\n    from {sp_llm_qs_location}.questionsVec\n    where 1=1\n        and transcriptComponentTypeId = 3\n)\nselect \n    q.callDate, q.enteredDate, q.fiscalYearQuarter, q.calendarYearQuarter,\n    q.tradingItemId, q.companyId, q.companyName, q.headline, q.transcriptId,\n    q.questionSpeakerTypeName, q.questionTranscriptPersonName, q.questionTranscriptPersonId, q.questionProId, \n    a.speakerTypeName as answerSpeakerTypeName, a.transcriptPersonName as answerTranscriptPersonName, a.transcriptPersonId as answerTranscriptPersonId, a.proId as answerProId, \n    q.questionTranscriptComponentTypeId, a.transcriptComponentTypeId as answerTranscriptComponentTypeId,\n    q.questionTranscriptComponentId, a.transcriptComponentId as answerTranscriptComponentId,\n    q.currentQuestionOrder, q.nextQuestionOrder, a.componentOrder as answerOrder, a.sentenceIndex as answerSentenceOrder,\n    q.question, a.componentText as answer, a.sentence as answerSentence, q.questionVec, a.sentenceVec as answerSentenceVec\n    , VECTOR_COSINE_SIMILARITY(questionVec, sentenceVec) AS cosine_similarity\nfrom q\n    join {sp_llm_qs_location}.answerSentencesVec a on q.tradingItemId = a.tradingItemId and q.transcriptId = a.transcriptId and a.componentOrder between q.currentQuestionOrder and ifnull(q.nextQuestionOrder, 10000)\norder by q.nextQuestionOrder asc, a.componentOrder asc, a.sentenceIndex asc\n\n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_qaPairCos\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87af385b-50e0-4574-b7cf-5ededd2124fb",
   "metadata": {
    "name": "md_633_cosine_sim_q_prep_remarks",
    "collapsed": false
   },
   "source": "### 6.3.3 Apply Cosine Similarity to Question & Prepared Remarks Vector Embeddings\nThe cell below pairs all prepared remarks sentences to questions. Then the the consine similarity was applied to the question and prepared remarks sentence vector embeddings."
  },
  {
   "cell_type": "code",
   "id": "05c85911-dbe1-4011-944c-340631482f72",
   "metadata": {
    "language": "python",
    "name": "py_calc_cosine_sim_q_prep_remark",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\nwith q as(\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter,\n        tradingItemId, companyId, companyName, headline, transcriptId,\n        speakerTypeName as questionSpeakerTypeName, transcriptPersonName as questionTranscriptPersonName,\n        transcriptPersonId as questionTranscriptPersonId, proId as questionProId, transcriptComponentTypeId as questionTranscriptComponentTypeId,\n        transcriptComponentId as questionTranscriptComponentId, componentOrder as currentQuestionOrder, lead(componentOrder) over (partition by tradingItemId, transcriptId order by componentOrder) as nextQuestionOrder, componentText as question, componentTextVec as questionVec\n    from {sp_llm_qs_location}.questionsVec\n    where 1=1\n        and transcriptComponentTypeId = 3\n)\nselect \n    q.*, \n    p.componentOrder as executiveRemarkComponentOrder, p.sentenceIndex as executiveRemarkSentenceOrder,\n    p.componentText as executiveRemark, p.sentence as executiveSentence, p.sentenceVec as executiveVec,\n    VECTOR_COSINE_SIMILARITY(questionVec, p.sentenceVec) as similarity\nfrom q\n    join {sp_llm_qs_location}.pppSentencesVec p on q.tradingItemId = p.tradingItemId and q.transcriptId = p.transcriptId\n\norder by q.nextQuestionOrder asc, p.componentOrder asc, p.sentenceIndex asc\n\n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_pppQPairCos\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50df1066-d89b-42ad-b7b9-ae16a5e4b409",
   "metadata": {
    "name": "md_64_top60_sentences",
    "collapsed": false
   },
   "source": "## 6.4 Top 60% Sentences\nUtilizing the top 60% of prepared remarks identified as generating the most consistent LLM output. For further details on the experiment, please refer to the 'LLM Robustness Check' section in the whitepaper.\n\n### 6.4.2 Concat Top 60% Answer Sentences\nAfter selecting the top 60% most similar answer sentences, we concat the answer sentences on the question level."
  },
  {
   "cell_type": "code",
   "id": "333f44d6-4e82-46a3-8faa-7962e287ea87",
   "metadata": {
    "language": "python",
    "name": "py_concat_top_60_answers",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ndf = session.sql(f'''\n          \n    with qaSimilarityRank as(\n    select \n        *, \n        ROW_NUMBER() OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder, currentQuestionOrder ORDER BY cosine_similarity desc) AS similarityRank,\n        COUNT(*) OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder, currentQuestionOrder) AS answerSentencesCount \n    from {sp_llm_qs_location}.TranscriptComponents_qaPairCos \n    ), \n    questionWithSixtyPercentAnswers as(\n\n    select \n        *, \n        case \n            when answerSentencesCount = 1 then 1\n            when similarityRank <= answerSentencesCount * 0.67 then 1\n            else 0\n        end as toKeepFlag\n    from qaSimilarityRank\n\n    ),\n    qaPair60 as(\n    select\n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName\n        , headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId\n        , questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId\n        , questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId\n        , answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, question, answer, \n        ARRAY_TO_STRING(ARRAY_AGG(answerSentence), ' ') AS sixtyPercentAnswer\n    from (select * from questionWithSixtyPercentAnswers where toKeepFlag = 1 order by currentQuestionOrder asc, answerOrder asc, answerSentenceOrder asc)\n    group by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId, questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId, answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, question, answer)\n    select \n        callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerSpeakerTypeName, answerTranscriptPersonName, answerTranscriptPersonId, answerProId, questionTranscriptComponentTypeId, answerTranscriptComponentTypeId, questionTranscriptComponentId, answerTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, answerOrder, \n        question, answer\n        , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',answer) as answerTokenCount\n        , sixtyPercentAnswer\n        , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',sixtyPercentAnswer) as sixtyPercentAnswerTokenCount\n    from qaPair60\n    order by currentQuestionOrder asc, answerOrder asc\n              \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_qaPairTop60\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa16aa95-4ae8-4df0-95a2-d1f9ed43f30f",
   "metadata": {
    "name": "md_643_concat_top60_prep_remarks",
    "collapsed": false
   },
   "source": "### 6.4.3 Concat Top 60% Prepared Remarks Sentences\nSimilarly, after selecting the top 60% most similar prepared remarks sentences, we concat the prepared remarks sentences on the question level."
  },
  {
   "cell_type": "code",
   "id": "d9d72152-56ec-48e6-918a-668638042c6b",
   "metadata": {
    "language": "python",
    "name": "cell41",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ndf = session.sql(f'''\n\nwith qaSimilarityRank as(\nselect \n    *, \n    ROW_NUMBER() OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder ORDER BY similarity desc) AS similarityRank,\n    COUNT(*) OVER (PARTITION BY tradingItemId, transcriptId, currentQuestionOrder) AS executiveRemarksSentencesCount\nfrom {sp_llm_qs_location}.TranscriptComponents_pppQPairCos\n),\n\npppQPairTop60 as(\nselect \n    *, \n    case \n        when executiveRemarksSentencesCount = 1 then 1\n        when similarityRank <= executiveRemarksSentencesCount * 0.67 then 1\n        else 0\n    end as toKeepFlag\nfrom qaSimilarityRank),\n\npresenterLevelSixtyPercentPPP as(\nselect\n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, executiveRemarkComponentOrder, question, executiveRemark, \n    ARRAY_TO_STRING(ARRAY_AGG(executiveSentence), ' ') AS sixtyPercentExecutiveRemark\nfrom (select * from pppQPairTop60 where toKeepFlag = 1 order by currentQuestionOrder asc, executiveRemarkComponentOrder asc, executiveRemarkSentenceOrder asc)\ngroup by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, executiveRemarkComponentOrder, question, executiveRemark\norder by currentQuestionOrder asc,  executiveRemarkComponentOrder asc),\n\npppQPairTop60Concat as(\nselect \n\n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question,\n    ARRAY_TO_STRING(ARRAY_AGG(executiveRemark), '\\n\\n') AS questionLevelConcatenatedRawExecutiveRemark,\n    ARRAY_TO_STRING(ARRAY_AGG(sixtyPercentExecutiveRemark), '\\n\\n') AS questionLevelConcatenatedSixtyPercentExecutiveRemark\nfrom (select * from presenterLevelSixtyPercentPPP order by currentQuestionOrder asc,  executiveRemarkComponentOrder asc)\ngroup by callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question\n)\n\nselect \n    callDate, enteredDate, fiscalYearQuarter, calendarYearQuarter, tradingItemId, companyId, companyName, headline, transcriptId, questionSpeakerTypeName, questionTranscriptPersonName, questionTranscriptPersonId, questionProId, questionTranscriptComponentTypeId, questionTranscriptComponentId, currentQuestionOrder, nextQuestionOrder, question,\n    questionLevelConcatenatedRawExecutiveRemark\n    , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',questionLevelConcatenatedRawExecutiveRemark) as questionLevelConcatenatedRawExecutiveRemarkTokenCount, questionLevelConcatenatedSixtyPercentExecutiveRemark\n    , SNOWFLAKE.CORTEX.COUNT_TOKENS('{completion_model}',questionLevelConcatenatedSixtyPercentExecutiveRemark) as questionLevelConcatenatedSixtyPercentExecutiveRemarkTokenCount\nfrom pppQPairTop60Concat\norder by currentQuestionOrder asc\n\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_pppQPairTop60\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ddb0cf0-76c9-49f2-bab2-41de606b73ce",
   "metadata": {
    "name": "md_7_llm_ready_data",
    "collapsed": false
   },
   "source": "# 7. Working with the Data: LLM Ready Data\n\nUsing a LLM to answer analysts questions based only on the prepared remarks and the previous questions and answers will give an indication if executives are proactive.\n\n## 7.1 Using Snowflake Cortex AI\nWhen calling the Snowflake Cortex COMPLETE function, messages are organized into distinct roles—system, user, and assistant—to structure and guide interactions. Each role serves a specific purpose:\n\nSystem: Provides instructions that define the context or behavior of the model. It's like setting the rules or tone for the conversation. Example: \"You are a helpful assistant that answers questions about technology in a concise manner.\"\n\nUser: Represents the input or queries made by the person interacting with the model. These are the prompts or requests that the model responds to. Example: \"What is the purpose of the OpenAI API?\"\n\nAssistant: Reflects the model's response to the user's query, shaped by the system's instructions and the user's input. Example: \"The OpenAI API is designed to enable developers to integrate language models into their applications for tasks like answering questions, generating content, and more.\"\n\nIn our research, executive prepared remarks are labelled as assistant messages, analyst's questions as User messages and executive answers as Assistant messages\n\n### 7.1.1 Construct COMPLETE Assistant Message with QA Pair Snippet"
  },
  {
   "cell_type": "code",
   "id": "ee6e5fe0-f534-4ee3-91fe-ae46983f0e1d",
   "metadata": {
    "language": "python",
    "name": "py_construct_QA_pair_snippet"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\nwith questionWithSixtyPercentAnswersPromptSnippet as (\n\nselect\n    *, \n    OBJECT_CONSTRUCT('role', 'user', 'content', REPLACE(question, '\\r', '')) as questionPromptSnippet,\n    OBJECT_CONSTRUCT('role', 'assistant', 'content', REPLACE(sixtyPercentAnswer, '\\r', '')) as answerPromptSnippet\n    \nfrom {sp_llm_qs_location}.TranscriptComponents_qaPairTop60)\nselect \n    *, ARRAY_CONSTRUCT(questionPromptSnippet, answerPromptSnippet) as questionAnswerPairPromptSnippet \nfrom questionWithSixtyPercentAnswersPromptSnippet\norder by currentQuestionOrder asc, answerOrder asc\n\n''')\n\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_pppQPairTop60AnswerConcat\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e3b400f-8459-48d4-980f-ab4b99582361",
   "metadata": {
    "name": "md_712_construct_complete_prompt",
    "collapsed": false
   },
   "source": "### 7.1.2 Construct Snowflake Cortex COMPLETE Assistant Message with Prepared Remarks Snippets"
  },
  {
   "cell_type": "code",
   "id": "36b8a7cf-1219-43b6-8b3d-3360973f8c1e",
   "metadata": {
    "language": "python",
    "name": "py_generate_assistan_messages"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\nselect\n    *,\n    OBJECT_CONSTRUCT('role', 'user', 'content', REPLACE(question, '\\r', '')) as questionPromptSnippet,\n    OBJECT_CONSTRUCT('role', 'assistant', 'content', REPLACE(questionLevelConcatenatedSixtyPercentExecutiveRemark, '\\r', '')) as pppPromptSnippet\nfrom {sp_llm_qs_location}.TranscriptComponents_pppQPairTop60\n\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_pppQPairTop60PPPConcat\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8652c71-32ee-4f1e-9972-24f0a47cb5b7",
   "metadata": {
    "name": "md_collect_complete_messages",
    "collapsed": false
   },
   "source": "## 7.2 Collect All Messages for Cortex COMPLETE\nAll question pairs with prepare remarks and answers come together to form an LLM prompt following the iterative process such that:\n\n1. 'user': 'From the perspective of a top executive, please answer the following question raised by a financial analyst during an earnings conference call. Knowledge cutoff date: '  \n2. 'assistant': 60% prepared remarks  \n3. 'user': question 1  \n4. 'assistant': 60% answer 1  \n5. ...  \n6. ...  \n7. 'user': question n  \n\n### 7.2.1 LLM Ready Prompt Messages\nIn the dataframe below, the prompt column has all the messages in 1 list. This is the prompt for the LLM."
  },
  {
   "cell_type": "code",
   "id": "9fd9ee2a-5d11-4c02-a8a6-27d28d27f0e6",
   "metadata": {
    "language": "python",
    "name": "py_construct_full_prompt"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n    with pppQPairTop60PPPConcat\n    as\n    (\n    select \n         a.callDate, a.tradingItemId, a.transcriptId, a.headline, \n        a.questionTranscriptPersonName, a.questionTranscriptPersonId, a.questionProId,\n        a.answerTranscriptPersonName, a.answerTranscriptPersonId, a.answerProId,\n        a.questionTranscriptComponentId, a.answerTranscriptComponentId,\n        a.question, a.answer,\n        ARRAY_CONSTRUCT(object_construct('role', 'user', 'content', concat('From the perspective of a top executive, please answer the following question raised by a financial analyst during an earnings conference call. Knowledge cutoff date: ', cast(a.callDate as string)))) as initPrompt,\n       a.questionPromptSnippet,\n       ARRAY_FLATTEN(ARRAY_AGG(a.questionAnswerPairPromptSnippet) OVER (PARTITION BY a.TRANSCRIPTID ORDER BY a.CURRENTQUESTIONORDER \n                                                        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)) as concatenatedPredecessors\n     from {sp_llm_qs_location}.TranscriptComponents_pppQPairTop60AnswerConcat a\n    )\n    select a.* \n        , ARRAY_CAT(a.initPrompt, ARRAY_CAT([ppp.pppPromptSnippet], ARRAY_CAT(a.concatenatedPredecessors, [a.questionPromptSnippet]))) as prompt\n    from \n    pppQPairTop60PPPConcat a\n    join {sp_llm_qs_location}.TranscriptComponents_pppQPairTop60PPPConcat as ppp on a.tradingItemId = ppp.tradingItemId and a.transcriptId = ppp.transcriptId and a.questionTranscriptComponentId = ppp.questionTranscriptComponentId\n    order by a.questionTranscriptComponentId asc, a.answerTranscriptComponentId asc\n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMReadyPrompt\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c509c9a6-2350-4293-9acc-1fb5c540830e",
   "metadata": {
    "name": "md_73_collect_COMPLETE_responses",
    "collapsed": false
   },
   "source": "## 7.3 Collect LLM Response\n\n### 7.3.1 Apply LLM Completion\nWe apply the SNOWFLAKE.CORTEX.COMPLETE function on the prompt column using the model defined by `completion_model`and collect the LLM response."
  },
  {
   "cell_type": "code",
   "id": "ca81a278-6b25-4b8c-9345-93bb753d9aff",
   "metadata": {
    "language": "python",
    "name": "py_call_complete",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select *,  SNOWFLAKE.CORTEX.COMPLETE('{completion_model}', prompt, {{'temperature': 0}}) as LLMAnswer \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMReadyPrompt\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0035b140-240c-45bd-8d0a-e51764d0a3eb",
   "metadata": {
    "name": "md_732_clean_up_LLM_responses",
    "collapsed": false
   },
   "source": "### 7.3.2 Clean Up LLM Response\n\nExtract only the actual message from the LLM from the responses"
  },
  {
   "cell_type": "code",
   "id": "62333d10-d5e7-48fa-8e0d-0aa93fb66e10",
   "metadata": {
    "language": "python",
    "name": "py_extract_message"
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select \n        callDate, tradingItemId, transcriptId, headline, \n        questionTranscriptPersonName, questionTranscriptPersonId, questionProId, answerTranscriptPersonName, answerTranscriptPersonId, answerProId,\n        questionTranscriptComponentId, answerTranscriptComponentId, question, answer,\n        REPLACE(LLMANSWER: \"choices\"[0]: \"messages\", '\"', '') as cleanLLMAnswer \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Clean\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb29bb53-5a68-4d00-978a-6302b1eb16a8",
   "metadata": {
    "name": "md_74_summarize_text",
    "collapsed": false
   },
   "source": "## 7.4 Summarize Text\n\nUse the Snowflake Cortex Summarize function to summarize the question, answer and LLM answer"
  },
  {
   "cell_type": "code",
   "id": "6d5c15c2-52f1-4dc0-9a7d-2ea683ec2391",
   "metadata": {
    "language": "python",
    "name": "py_summarize",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f\"\"\"\n\n    select \n        *, \n        SNOWFLAKE.CORTEX.SUMMARIZE(question) as summarizeQuestion,\n        SNOWFLAKE.CORTEX.SUMMARIZE(answer) as summarizeAnswer,\n        SNOWFLAKE.CORTEX.SUMMARIZE(cleanLLMAnswer) as summarizeCleanLLMAnswer,\n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Clean\n          \n\"\"\")\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cde8c8fb-317d-40ec-b17b-a7efc118fc78",
   "metadata": {
    "name": "md_8_factor_construction",
    "collapsed": false
   },
   "source": "# 8. Working with the Data: Factor Construction\n## 8.1 Executive On/Off Topic Factor\nWhen an executive answer is semantically similar (dissimilar) to the analyst’s question, it suggests that the answer uses language and concepts similar to (different from) the analyst question, indicating it is on-topic (off-topic). To determine semantic closeness, we vector-embed the question-and-answer texts and calculate a cosine similarity score between the two vectors.\n\n### 8.1.1 Question vs Executive Answer Cosine Similarity"
  },
  {
   "cell_type": "code",
   "id": "ffc83173-e945-42e1-a8ce-3fe2785bd834",
   "metadata": {
    "language": "python",
    "name": "py_q_v_a_cosine_sim",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select *\n        , {snf_embed_text_func}('{embedding_model}', summarizeQuestion) as questionVec\n        , {snf_embed_text_func}('{embedding_model}', summarizeAnswer) as answerVec \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, answerVec) as execOnOffTopicFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_execOnOffTopicFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38be14f8-7a72-4aab-984c-43aa3e76ff97",
   "metadata": {
    "name": "md_812_mean_on_off_topic",
    "collapsed": false
   },
   "source": "### 8.1.2 Transcript Mean Executive On/Off Topic Factor\nCosine similarity scores are averaged at the transcript level. A high (low) Cosine Similarity Score indicates an On (Off) Topic Executive.\n\n"
  },
  {
   "cell_type": "code",
   "id": "9c2f2ed4-20eb-4ff6-a527-05c9362b066f",
   "metadata": {
    "language": "sql",
    "name": "sql_mean_on_off_topic"
   },
   "outputs": [],
   "source": "select avg(execOnOffTopicFactor) as transcriptLevelExecOnOffTopicFactor \nfrom {{sp_llm_qs_location}}.TranscriptComponents_execOnOffTopicFactor",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "916210b3-8d62-4bac-9a1a-13fbc0d08ffc",
   "metadata": {
    "name": "md_82_executive_pro_re_factor",
    "collapsed": false
   },
   "source": "## 8.2 Executive Proactive/Reactive Factor\n### 8.2.1 Question vs LLM Answer Cosine Similarity\nSince the LLM answers only within the context of information provided in the prepared remarks, a high (low) cosine similarity score indicates that the LLM answers are semantically similar (dissimilar) the questions, reflecting the executives are proactive (reactive)."
  },
  {
   "cell_type": "code",
   "id": "06d679e9-5849-44cd-b73a-595e4a9df160",
   "metadata": {
    "language": "python",
    "name": "py_q_llmA_cosine_sim"
   },
   "outputs": [],
   "source": "df = session.sql(f'''\n\n    with vec as(\n    select \n        *, \n        {snf_embed_text_func}('{embedding_model}', summarizeQuestion) as questionVec, \n        {snf_embed_text_func}('{embedding_model}', summarizeCleanLLMAnswer) as LLMAnswerVec \n    from {sp_llm_qs_location}.TranscriptComponents_targetLLMAnswer_Summarize\n    )\n    select *, VECTOR_COSINE_SIMILARITY(questionVec, LLMAnswerVec) as execProactiveReactiveFactor from vec \n               \n''')\n\ndf.write.save_as_table(f\"{sp_llm_qs_location}.TranscriptComponents_execProactiveReactiveFactor\", mode=\"overwrite\", table_type='transient')\ndf.limit(5)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5999994a-81e2-428f-ab24-4a5eeb72e150",
   "metadata": {
    "name": "md_822_mean_pro_re_factor",
    "collapsed": false
   },
   "source": "### 8.2.2 Transcript Mean Executive Proactive/Reactive Factor\nSimilar to the construction of the Executive On/Off Topic factor, both the LLM answers and questions are summarized, vector-embedded and cosine similarity scores are averaged at the transcript level."
  },
  {
   "cell_type": "code",
   "id": "79c48dfb-ca72-41ba-af86-d0f5975d6c48",
   "metadata": {
    "language": "sql",
    "name": "sql_mean_pro_re_factor"
   },
   "outputs": [],
   "source": "select avg(execProactiveReactiveFactor) as transcriptLevelexecProactiveReactiveFactor \nfrom {{sp_llm_qs_location}}.TranscriptComponents_execProactiveReactiveFactor",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e4c3c21-f09e-4994-aa9a-1db01028f0d3",
   "metadata": {
    "name": "md_9_result_summary",
    "collapsed": false
   },
   "source": "# 9. Results & Summary\nThis research underscores the significant impact of executive communication styles during earnings calls on firm performance. Proactive executives who anticipate market concerns and provide concise, on-topic responses foster transparency, aligning with investor expectations and driving superior returns. The findings demonstrate that firms with Efficient Communicators achieve statistically significant outperformance, while Total Redirectors suffer from diminished confidence and underperformance. These insights validate the critical role of strategic communication in shaping investor perceptions and influencing market outcomes.\n\nAdvanced analytical tools, such as vector embeddings and cosine similarity metrics, enable nuanced evaluations of executive-analyst interactions, revealing measurable performance effects across different communication styles. While large language models (LLMs) enhance feature extraction, challenges like forward-looking bias and inconsistency highlight the need for caution in time-sensitive tasks. Overall, the integration of proactive, clear, and relevant communication strategies remains paramount in fostering investor trust and maximizing financial success in a competitive marketplace."
  }
 ]
}